\chapter{Search for the cH(ZZ$\rightarrow$4$\mu$) process}
To probe the charm Yukawa coupling through the cH process, a methodology must be devised to select and reconstruct cH candidate events.  This is described in \autoref{sec:Selection}, specifically targetting \cHZZ final states. Additionally, a model describing the expected contributions from the \cHZZ process as well as a number of background processes in the event selection must be constructed and is described in \autoref{sec:s+bEstimation}. Finally, a statistical evaluation method using flavour-tagging discriminators to set 95\% CL upper limits on $\kappa_c$, assuming the absence of signal, is presented in \autoref{sec:StatisticalEvaluation}.

\section{cH event selection}
\label{sec:Selection}
To reconstruct a \cHZZ candidate event, a Higgs boson candidate needs to be reconstructed and a corresponding jet candidate needs to be identified. These two procedures are described in this section. Distributions of \cHZZ candidate events are shown using a simulation of the \cHZZ process, which is discussed in \autoref{sec:cHSimulation}. \\
\\
To reconstruct a Higgs (jet) candidate, an initial selection of muon (jet) objects must be made. These are summarised in \autoref{table:objectSelection} along with the HLT trigger path requirement used in this analysis. The objective of this selection is to identify events with well-reconstructed, isolated muons as well as a least on well-reconstructed jet. Following this initial selection, the corresponding objects are passed onto the respective algorithms to select a final Higgs and jet candidate. 

\begin{table}[H]
    \centering
    \caption[]{Muon, jet object and HLT path selection requirements.}
    \begin{adjustbox}{width=0.6\textwidth}
    \label{table:objectSelection}
        \begin{tabular}{l l }
        \toprule 
        \textbf{Object} & \textbf{Selection criteria} \\
        \midrule 
        \midrule
        Muons & \pt \, \textgreater \, 5 GeV \\
        & $\mid$$\eta$$\mid$ \textless \, 2.4 \\
        & Tight muon identification criteria \\
        \midrule
        Jets & \pt \, \textgreater \, 25 GeV \\
        & $\mid$$\eta$$\mid$ \textless \, 2.5 \\
        & Jet ID \\
        & Pile-up ID, loose working point \\
        & $\Delta R$(jet, selected muons) \textgreater \, 0.4 \\
        & Jets in veto regions of detector are excluded \\
        \midrule 
        HLT & HLT\_IsoMu24 is triggered\\
        \bottomrule
        \end{tabular} 

    \end{adjustbox}
\end{table}

\subsection{Higgs candidate selection}
A Higgs boson reconstruction algorithm (and muon object selection) very similar to those presented and validated in \cite{HIG19-001} is implemented. This reconstruction is performed for events in which exactly four selected muons are present to avoid introducing a potential bias when reconstructing non-Higgs (background) events. Then the following reconstruction steps are applied:
\begin{enumerate}
    \item Of the four selected muons, the \pt-leading muon is required to satisfy \pt \, \textgreater 20 GeV and the sub-leading muon is required to satisfy \pt \,\textgreater 10 GeV. Additionally, the HLT\_IsoMu24 trigger requirement must be met. Lastly, to ensure two muons are not spuriously reconstructed from shared tracks, it is required that each muon candidate is separated from the others by $\Delta$R \textgreater 0.02. 
    \item Opposite-sign muon pairs are merged into Z boson candidates. At least two Z boson candidates must be reconstructed to proceed. Additionally, the invariant mass of any combination of oppsite-sign muons must satisfy $m_{\mu\mu}$\textgreater \, 4 GeV, to remove any contributions from low mass resonances such as J/$\psi$. 
    \item The Z candidate with a mass closest to the known Z boson mass of Z = 91.19 GeV \cite{PhysRevD.110.030001} is interpreted as an on-shell $Z_1$ candidate. The $Z_1$ candidate should satisfy 40 GeV \textless \, $m_{Z_{1}}$ \textless \, 120 GeV. The other candidate is taken as the $Z_2$ candidate, which is typically more off-shell and thus the invariant di-muon mass requirement is relaxed to 12 GeV \textless \, $m_{Z_{1}}$ \textless \, 120 GeV. 
    \item The $Z_1$ and $Z_2$ candidates are combined to form a Higgs boson candidate. The four-muon invariant mass of the Higgs boson candidate must satisfy $m_{H}$ \textgreater \, 70 GeV. 
\end{enumerate}
The reconstructed Higgs boson candidate mass distribution in simulated \cHZZ events can be seen in \autoref{fig:cHHiggsMass}. As expected, a peak around the known Higgs mass $m_{H}$ = 125.3 GeV can be oberserved, with an elongated tail towards lower masses that originate from increasingly off-shell Z candidate contributions. 
\subsection{Jet candidate selection}
\label{sec:JetCandidateSelection}
Once a Higgs boson candidate is reconstructed, a likelihood ratio algorithm is applied to best identify and select the jet that is associated with (i.e. recoils off) the reconstructed Higgs boson. This algorithm does not use jet-flavour identification methods and is based solely on kinematic properties of the jets so as to minimise the introduction of any flavour bias in the selection. Specifically, two variables related to momentum conservation in the transverse plane are exploited: 
\begin{enumerate}
    \item The difference in azimuthal angle $\Delta\phi$(H, jet) between the Higgs boson candidate H and the jet is used. Due to an initial zero net momentum in the direction of the azimuthal angle, the Higgs boson and associated jet are expected to recoil off eachother \textit{back-to-back} and thus $\Delta\phi$(H, jet) is expected to be $\sim \pm \pi$.
    \item Since the Higgs boson and associated jet recoil off eachother, their \pt \, is expected to be approximately balanced. This information can be captured by transverse momentum ratio $p_{\mathrm{T}}(H)$/$p_{\mathrm{T}}(\mathrm{jet})$. 
\end{enumerate}
To derive the relevant distributions to be used in a likelihood ratio, a parton-to-jet matching is performed in simulated \cHZZ events. This is achieved by, in a simulated event, taking the directional information of the simulated parton and matching it to a reconstructed jet with the matching requirement $\Delta R(\mathrm{jet, parton})$ \textless 0.3. All jets which match the initial jet selection are considered for this process and a matching efficiency of $\sim$80\% is achieved for events in which the parton is a charm quark  while an efficiency of $\sim$75\% is achieved for events in which the parton is a gluon. A jet which is matched in this way is labelled as the associated jet, while the remaining non-matched jets are labelled non-associated jets. Once this labelling is performed, the distributions of both kinematic variables are extracted as templates for both associated and non-associated jets and treated as probability density functions. To capture kinematic differences associated with higher and lower \pt \, Higgs candidates, this procedure is repeated in different bins of \pt(H) listed in \autoref{table:JetSelectionHiggsBins}. The templates that are extracted in this way can be seen in Appendix \autoref{sec:JetSelectionTemplates}. \\
\\
Using the extracted templates, a per-jet likelihood evaluation can be made in each event. For this, the per-variable likelihood ratio 
\begin{align}
    \mathcal{L}(x) = \frac{\mathcal{L}_{\mathrm{associated}}(x)}{\mathcal{L}_{\mathrm{non-associated}}(x)}, \,
    \mathrm{with} \, x \in \Big\{ \Delta\phi\mathrm{(H, jet)}, \frac{p_{\mathrm{T}}(H)}{p_{\mathrm{T}}(\mathrm{jet})} \Big\}
\end{align}
is defined. From this follows the per-jet likelihood 
\begin{align}
    \mathcal{L}(\mathrm{jet}) = \mathcal{L}\Big(\Delta\phi\mathrm{\big(H, jet\big)}\Big) \mathcal{L}\Bigg(\frac{p_{\mathrm{T}}(H)}{p_{\mathrm{T}}(\mathrm{jet})}\Bigg)
\end{align}
that is evaluated. The jet with the highest associated likelihood in an event is selected as the jet candidate. 
\begin{table}[H]
    \centering
    \caption[]{The \pt(H) bins in which the jet selection procedure is performed.}
    \begin{adjustbox}{width=0.4\textwidth}
    \label{table:JetSelectionHiggsBins}
        \begin{tabular}{l l l l l}
        \toprule 
        \textbf{Bin number} & \textbf{\pt(H) range} \\
        \midrule 
        \midrule
        1 & 0 - 15 GeV \\
        2 & 15 - 30 GeV \\
        3 & 30 - 50 GeV \\
        4 & 50 - 100 GeV \\
        5 & 100 - 200 GeV \\
        6 & \textgreater 200 GeV \\
        \bottomrule
        \end{tabular} 

    \end{adjustbox}
\end{table}
\noindent With this, the individual components of the \cHZZ process are thus reconstructed and events satisfying the described requirements are selected for evaluation. 

\subsection{Reconstruction efficiency}
A total selection efficiency of $\sim$10\% is achieved on the simulated \cHZZ sample using the described methods. The losses in efficiency can be attributed to the following:
\begin{itemize}
    \item Approximately 50\% of generated events fall outside of the geometrical detector acceptance.
    \item Of the 50\% of generated events within the geometrical detector acceptance, approximately 50\% fulfill the described muon selection requirements.
    \item Approximately 91\% of these events pass the Higgs reconstruction, leading to an additional event yield loss of 9\%
    \item Of the remaining events, the event yield is reduced by close to 60\% by the jet selection requirements that are imposed. 
\end{itemize}
Also of interest is the efficiency with which the jet associated with the Higgs boson is selected in simulated \cHZZ events with the described jet selection method. For events in which more than one jet passes the jet requirements, an efficiency of 68\% is achieved for associated jet transverse momenta below 50 GeV, with the efficiency exceeding 90\% for associated jet transverse momenta above 50 GeV. This can be seen in \autoref{fig:jetSelectionEfficiency}. It should be noted that this calculation only accounts for events in which an associated parton is generated at the matrix element level (see \autoref{sec:cHSimulation} for more details) and in which the parton can be matched to a jet. 

\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{figures/jetSelectionEfficiency.pdf}
    \caption{The efficiency with which the jet associated with the Higgs boson is selected via the described algorithm in simulated \cHZZ events. This efficiency is shown in bins of the associated jet's transverse momentum for events in which more than one jet passes the jet selection requirements.}
    \label{fig:jetSelectionEfficiency}
\end{figure}

\section{Signal and background estimation}
\label{sec:s+bEstimation}
The \cHZZ process as well as background processes which may mimic its signature must be estimated to accurately reflect the underlying processes as well as their interaction with the detector. This is done primarily using Monte Carlo simulations, which are described in \autoref{sec:MonteCarlo}. The simulation of the \cHZZ process is specifically discussed in \autoref{sec:cHSimulation}. The estimation of processes that make up the irreducible and reducible backgrounds to the \cHZZ process is discussed in \autoref{sec:IrreducibleBackgrounds} and \autoref{sec:ReducibleBackgrounds} respectively. From these estimations, a comprehensive model of the expected yields and distributions that would result from applying the described selection on the 2018 dataset of the CMS detector can be constructed. 

\subsection{Monte Carlo simulation of proton-proton collisions}
\label{sec:MonteCarlo}
Since the complexity of a proton-proton collisions in a detector cannot realistically be captured by analytic calculations, Monte Carlo methods \cite{MonteCarlo} can be used as an approximation. The concept of such a simulation relies on a phenomenoligcal approach, sampling the known distributions of process and detector quanities and properties to construct a comprehensive simulation of a process and its interaction with the detector. The simulation process occurs in discrete steps, each dealing with different aspects of the simulated process. These can be summarised as: 

\begin{enumerate}
    \item \textbf{The hard scattering process}: The hard scattering process refers to the immediate, high energy transfer scattering of two protons resulting in the production of additional particles. To calculate this, two main ingredients are required. The first is a calculation of the matrix elements that describe the simulated process in which proton constituents collide to produce additional particles. These matrix elements allow for the calculation of a cross section for the process. However, the proton itself is a complex object consisting not only of its valence quarks (two up-type quarks and one down-type quark) but also of a constantly changing ensemble of additional quarks and gluons that are created and annihilated. This behaviour must thus be captured for an accurate process description and is parametrised via so-called \textit{Parton Distribution Functions}. These describe the likelihood with which a parton, that carries some fraction $x$ of the protons total momentum, may be found in a proton at some energy scale Q$^2$. The evolution of the PDF with changing Q$^2$ is described by the DGLAP quations \cite{DGLAP}. Software used to simulate the hard scattering are referred to as \textit{event generators}. Commonly used event generators include \textsf{Madgraph5\_aMC$@$NLO} \cite{MadGraph} and \textsf{POWHEG} \cite{POWHEG}. 
    \item \textbf{Parton showering}: Particles such as quarks and gluons that are produced in the hard scattering carry the colour charge of the strong interaction. As a result, these may produce soft radiation or branch into other particles. While a most physically accurate description would be given by including these contributions in the calculation of the hard scattering process, this greatly increases the complexity of the calculation. As such a \textit{parton shower} model, such as in the \textsf{Pythia} software package \cite{PYTHIA}, is used instead to describe the splitting of a single mother particle into two daughter particles. In QCD, this describes to gluon radiation ($q\rightarrow qg$) and gluon splitting ($g\rightarrow gg$ and $g \rightarrow q \overline{q}$) and in QED describes Bremsstrahlung ($f\rightarrow f\gamma$) and pair creation ($\gamma \rightarrow f \overline{f}$). In case this the parton showering originates from initial state partons it is referred to as initial state radiation (ISR). Accordingly, parton showering originating from final state partons is referred to as final state radiation (FSR). In cases with final states containing multiple partons, there can be some ambiguity in the combination of matrix elements and parton showering since both can describe the same processes. For this merging schemes are applied that resolve potential double counting of events. A prescription used for this work is the FxFx scheme \cite{FxFx}. 
    \item \textbf{Hadronisation}: At an energy around the QCD scale $\Lambda_{\mathrm{QCD}}$, the perturbative parton shower prescription loses its validty as the running coupling of the strong force $\alpha_{s}$ becomes too strong. Here the individual, colour-charged partons \textit{hadronise} into colour-neutral states.  Since this process currently cannot be described from first principles, a phenomenological description must be applied. In \textsf{Pythia}, the \textit{Lund string} model is used \cite{LundStringModel}. It describes the interaction between two partons as a coloured field, the lines of which pass through a tube that is extended between the partons. The potential energy of the tube (or string) is described by a term linear in the distance between the partons. Thus if the partons are separated at a large enough distance and the potential energy is sufficiently large, the string may 'break' and new colourless quark-antiquark pairs are formed. This procedure may be repeated with these new parton pairs if they posses an invariant mass above some threshold. 
    \item \textbf{The underlying event}: A description of a variety of effects secondary to the hard scattering must be included in the simulation. These can have several origins such as secondary, \textit{soft} interactions of the proton-proton collision or remnants of the collided protons, which will hadronise themselves. These effects are modeled from data \cite{UnderlyingEvent}.
    \item \textbf{Detector simulation}: Finally, the detector response to the particles emerging from the previously describeds steps must be simulated. This is performed with the \textsf{GEANT4} package \cite{GEANT4}, which is configured to model the CMS detector. This includes modelling the curving of particle trajectories due to the detector's magnet, the interaction of particles with the materials of the detector, as well as the digitisation of the signals in the electronic modules of the subdetectors.
\end{enumerate}
A diagrammatic overview of what an event simulation looks like can be found in \autoref{fig:EventSimulation}. The output of this simulation is passed to the reconstruction algorithms described in \autoref{sec:Reconstruction}.

\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{figures/EventSimulation.png}
    \caption{An overview of what an event simulation may look like (adapted from \cite{Hoche:2014rga}). }
    \label{fig:EventSimulation}
\end{figure}

\subsection{Estimation of \cHZZ process}
\label{sec:cHSimulation}
The \cHZZ process is estimated using a simulation generated by \textsf{MadGraph5\_aMC@NLO}. The following \textsf{MadGraph5\_aMC@NLO} syntax is used, which illustrates some important concepts related to the simulation of the cH process:
\begin{itemize}
    \label{MadGraphcHCommand}
    \itemsep0em 
    \item[] import model loop\_sm\_MSbar\_yb\_yc-yc4FS 
    \item[] define p = g u u$\sim$ d d$\sim$ s s$\sim$ c c$\sim$ 
    \item[] define j = g u u$\sim$ d d$\sim$ s s$\sim$ c c$\sim$ 
    \item[] generate p p \textgreater h [QCD] @ 0 
    \item[] generate p p \textgreater h j [QCD] @ 1
\end{itemize}
In the first line, it can be read off that the \textsf{loop\_sm} model is used, a model allowing NLO calculations of the SM. Only the Yukawa-couplings of the bottom and charm quarks are included to ensure orthogonality of the cH simulation to simulations of other Higgs production processes such as gluon fusion. Additionally, a so-called \textit{four flavour scheme} (4FS) version of the model is used \cite{}. The flavour scheme denotes which quarks are included as constituents of the proton, in which they are approximated as massless. The 4FS includes the up, down, strange and charm quarks as proton constituents. In contrast to the 4FS, a three flavour scheme 3FS could also be used. Here, the charm quark is not included in the proton but instead must be produced via gluon spllitting, i.e. $g \rightarrow c\overline{c}$. \\
\\
In the following two lines, the proton and jet constituents are defined. Finally in the last two lines, the processes included in the simulation are defined. These are, calculated to next to leading order in QCD, the $p p \rightarrow H$ and $p p \rightarrow H+j$ processes. Both are included to give the most accurate possible kinematic description of the cH process. The reasoning for this is related to the modelling of final state partons and can be better understood by considering what is included in the leading order (LO) and next-to-leading (NLO) contributions to $p p \rightarrow H$ and $p p \rightarrow H+j$ respectively. At leading order, an additional jet in $p p \rightarrow H$ can only be generated via the parton shower. Thus, this contribution is expected to best model the lower momentum behaviour of final state partons. The NLO contributions to $p p \rightarrow H$, which correspond to LO contritubtions of $p p \rightarrow H+j$, in turn are expected to better model higher momentum behaviour of the final state parton. The same logic is applied to the LO contributions of $p p \rightarrow H+j$ and the NLO contributions of $p p \rightarrow H+j$, where two final state partons explicitly appear in the calculation of the latter. However, this approach introduces double counting of processes. These are accounted for along with double counting between parton shower and matrix element contributions using the FxFx merging scheme.  \\
\\
The types of event topologies generated by these commands can be best understood by categorising them according to the partons that inititate them. In this way, four categories can be identified:
\begin{itemize}
    \item \textit{\textbf{c$\overline{\bm{c}}$}}: At leading order, this topology arises from an initial state c and anti-c quark that interact to produce a Higgs boson. Final state partons must thus be produced via next-to-leading order contributions to the matrix element (i.e. gluon radiation) or via parton showering. Notably, the charm quark(s) associated with the Higgs boson are not present in the final state of this type of topology. This means that for the described event selection strategy, this analysis can only be sensitive to these topologies via an `incorrect' jet association. A visualisation of this type of event topology can be seen in \autoref{fig:FeynmancHTopology0}. It is the most prominent in the generated sample. 
    \item \textit{\textbf{cg}}: At leading order, this topology arises from an initial state (anti-)c quark that emits a Higgs boson and absorbs a gluon. This topology corresponds to the leading order cH process that is discussed in \autoref{sec:thecHProcess}. Additional final state partons may be produced via next-to-leading order contributions to the matrix element or via parton showering. A visualisation of this type of event topology can be seen in \autoref{fig:FeynmancHTopology1}. It is the second most prominent in the generated sample. 
    \item \textit{\textbf{gg}}: This topology arises from two initial state gluon which split to form $c\overline{c}$ pairs that interact to produce a Higgs boson. Since this is already considered a next-to-leading order contribution to the matrix element by the generator, additional final state partons can only be generated via parton showering. A visualisation of this type of event topology can be seen in \autoref{fig:FeynmancHTopology2}. It contributes to only a small fraction of events in the generated sample.  
    \item \textit{\textbf{cl}}: This topology arises from an initial state (anti-)c quark that interacts with an additional initial state light quark via gluon exchange, which proces a Higgs boson. Since this is already considered a next-to-leading order contribution to the matrix element by the generator, additional final state partons can only be generated via parton showering. A visualisation of this type of event topology can be seen in \autoref{fig:FeynmancHTopology3}. Like the \textit{gg} topology, it contributes to only a small fraction of events in the generated sample.  
\end{itemize}
An overview of the relative occurrence of these topologies in the generated sample can be seen in \autoref{fig:cHTopologies}. Clearly, the \textit{c$\overline{c}$} topology dominates with a relative proportion $> 60\%$, while the $cg$ topology only comprises $\sim35\%$ of events. Since the jet identification plays no role in the former topology, it is worth considering how the selection algorithm described in \autoref{sec:Selection} affects the relative occurrence of each topology. This can be seen in \autoref{fig:cHTopologiesPostSelection}. Clearly, the selection algorithm (specifically the jet selection) introduces a significant bias towards $cg$ topologies as expected and desired. However, a relative porportion of close to 40\% of \textit{c$\overline{c}$} topologies remain, which may still contribute towards the sensitivity of the analysis. These are typically associated with light flavour jets. This motivates the use of an inclusive statistical evaluation strategy, exemplied by for example the use of the full CvsB and CvsL \textsf{DeepJet} distributions of the selected jet, in contrast to the cut-based approach presented in \cite{cmscHgammgamma}.  \\
\\
\begin{figure}
    \begin{subfigure}{.5\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{figures/METype_METypeNoSelection.pdf}
        \caption{Before applying selection algorithm.}
        \label{fig:cHTopologies}
    \end{subfigure}%
    \begin{subfigure}{.5\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{figures/METype_METype.pdf}
        \caption{After applying selection algorithm.}
        \label{fig:cHTopologiesPostSelection}
    \end{subfigure}%
    \caption{The relative occurrence of the \textit{c$\overline{c}$}, \textit{cg}, \textit{gg} and \textit{cl} event topologies in the simulated \cHZZ sample before and after applying the selection algorithm.}
\end{figure}
\begin{figure}
\begin{subfigure}{.5\textwidth}
    \centering
    \begin{tikzpicture}
    \begin{feynman}
        %\vertex[dot, color=red, size=1mm] at (2, 0.5) {\(y_c\)};
        \vertex at (0, 2) (i1);
        \vertex at (0,-2) (i2);
        \vertex at (2, 0) (b);
        \vertex at (4, 0) (o1);
        \diagram*{
            (i1) -- [plain, edge label'={\textit{c}}, near start] (a),
            (i2) -- [plain, edge label={\textit{c}}, near start] (a),
            (a) -- [scalar, edge label={\textit{H}}] (o1),
        };
    \end{feynman}
    \draw[fill=red] (a) circle(1mm);
    \end{tikzpicture}
    \caption{The $c\overline{c}$ topology at lowest order.}
    \label{fig:FeynmancHTopology0}
    \vspace{10mm}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
    \centering
    \begin{tikzpicture}
    \begin{feynman}
        \vertex at (0, 2) (i1);
        \vertex at (0,-2) (i2);
        \vertex at (1.5, 0) (a);
        %\vertex[color=red] at (4, 0) () {\(y_c\)};
        \vertex at (3.5, 0) (b);
        \vertex at (5, 2) (o1);
        \vertex at (5, -2) (o2);
        \diagram*{
            (i1) -- [plain, edge label={\textit{c}}, near start] (a),
            (i2) -- [gluon, edge label={\textit{g}}, near start] (a),
            (a) -- [plain, edge label={\textit{c}}] (b),
            (b) -- [scalar, edge label={\textit{H}}, near end] (o1),
            (b) -- [plain, edge label={\textit{c}}, near end] (o2);
        };
    \end{feynman}
    \draw[fill=red] (b) circle(1mm);
    \end{tikzpicture}
    \caption{The $cg$ topology at lowest order.}
    \label{fig:FeynmancHTopology1}
    \vspace{10mm}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
    \centering
    \begin{tikzpicture}
    \begin{feynman}
        \vertex at (-1, 1) (i1);
        \vertex at (-1, -1) (i2);
        \vertex at (1, 1) (i3);
        \vertex at (1, -1) (i4);
        \vertex at (2, 0) (a);
        %\vertex[color=red] at (4, 0) () {\(y_c\)};
        \vertex at (4, 2) (o1);
        \vertex at (4, -2) (o2);
        \vertex at (4, 0) (o3);
        \diagram*{
            (i1) -- [gluon, edge label={\textit{g}}] (i3),
            (i2) -- [gluon, edge label'={\textit{g}}] (i4),
            (i3) -- [plain, edge label={\textit{c}}] (a),
            (i4) -- [plain, edge label'={\textit{c}}] (a),
            (a) -- [scalar, edge label={\textit{H}}, near end] (o3),
            (i3) -- [plain, edge label={\textit{c}}, near end] (o1);
            (i4) -- [plain, edge label={\textit{c}}, near end] (o2);
        };
    \end{feynman}
    \draw[fill=red] (a) circle(1mm);
    \end{tikzpicture}
    \caption{The $gg$ topology at lowest order.}
    \label{fig:FeynmancHTopology2}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
    \centering
    \begin{tikzpicture}
    \begin{feynman}
        \vertex at (0, 0) (i1);
        \vertex at (0,-3.5) (i2);
        \vertex at (1.5, 0) (a);
        %\vertex[color=red] at (4, 0) () {\(y_c\)};
        \vertex at (2.5,-1.5) (b);
        \vertex at (2.5,-3.5) (d);
        \vertex at (4.5,0) (o1);
        \vertex at (4.5,-1.5) (o2);
        \vertex at (4.5,-3.5) (o3);
        \diagram*{
            (i1) -- [plain, edge label={\textit{c}}, near start] (a),
            (i2) -- [plain, edge label={\textit{l}}, near start] (d),
            (d) -- [gluon, edge label={\textit{g}}] (b),
            (a) -- [plain, edge label={\textit{c}}] (b),
            (a) -- [scalar, edge label={\textit{H}}, near end] (o1),
            (b) -- [plain, edge label={\textit{c}}, near end] (o2);
            (d) -- [plain, edge label={\textit{l}}, near end] (o3);
        };
    \end{feynman}
    \draw[fill=red] (a) circle(1mm);
    \end{tikzpicture}
    \caption{The $cl$ topology at lowest order.}
    \label{fig:FeynmancHTopology3}
\end{subfigure}
\caption{Examples of feynman diagrams that illustrate the four different event topologies generated in the \cHZZ sample at the lowest order. The red dots represent the \yc \, coupling.}
\end{figure}
\noindent{}To capture uncertainties associated with the choice of a particular flavour scheme in the simulation of \cHZZ, additional \cHZZ samples are used. These specifically simulate the \cHZZ process in the 3FS and 4FS, without the use of FxFx merging, effectively capturing cases where a charm \textit{must} originate from gluon splitting or directly from the proton respectively. From these samples, an uncertainty envelope is constructed for the discriminators distribution in the statistical evaluation presented in \autoref{sec:StatisticalEvaluation}. This envelope is determined by taking the relative discrepancy between the 3FS and 4FS samples and interpreting it as an uncertainty band around the the nominal 4FS FxFx sample distributions. An overview of all used signal samples can be seen in \autoref{table:SignalSamples}. \\
\\
\begin{table}[H]
    \centering
    \caption[]{\cHZZ samples used in this work}
    \begin{adjustbox}{width=0.7\textwidth}
    \label{table:SignalSamples}
        \begin{tabular}{l l l}
        \toprule 
        \textbf{Process} & \textbf{$\sigma$} & \textbf{\# of simulated events}\\
        \midrule 
        \midrule
        \cHZZ 4FS FxFx & & xx \\
        \cHZZ 3FS & & xx \\
        \cHZZ 4FS & & xx \\
        \bottomrule
        \end{tabular} 
    \end{adjustbox}
\end{table}

\subsection{Estimation of irreducible backgrounds}
\label{sec:IrreducibleBackgrounds}
Irreducible background processes are background processes that produce the same final state particles as the signal process in question. Thus, processes which produce four final state muons along with the presence of a, or several, jet(s) constitute the irreducible background. These again fall into two categories, namely those where the four muons originate from a Higgs boson and those in which they do not. When analysing e.g. the mass spectrum of Higgs candidates, the processes of the former category is thus clearly resonant around the Higgs mass of $\sim$125 GeV, while those of the latter category may take on a more continuous shape. The irreducible backgrounds condiered in this work are:\\
\begin{itemize}
    \item \textbf{Gluon fusion (ggH)}: In these processes, a pair of gluons produce an intermediary (top) quark pair loop that produces a Higgs boson. The Higgs boson decay may produce four muons while parton radiation may produce additional jets. An example Feynman diagram of the ggH process can be seen in \autoref{fig:ggH}. 
    \item \textbf{Top quark pair assocaited Higgs production(ttH)}: In ttH processes, a pair of top quarks is produced alongside a Higgs boson. The Higgs boson decay may produce four muons while the decay of the top quark pairs produces additional b jets. An example Feynman diagram of the ttH process can be seen in \autoref{fig:ttH}.
    \item \textbf{Vector boson associated Higgs production (VH)}: The vector boson produced alongside a Higgs boson may refer to W$^{\pm}$ and Z bosons. Thus, three different process types contribute to this background, namely $W^{+}$H,  $W^{+}$H and ZH. The Higgs boson decay may produce four muons while a W$^{\pm}$ boson decay as well as a Z boson decay may produce additional jets. An example Feynman diagram of these processes can be seen in \autoref{fig:VH}.
    \item \textbf{Vector boson fusion (qqH)}: In vector boson fusion processes, two vector bosons emitted by initial state quarks fuse to produce a Higgs boson. The Higgs boson decay may produce four muons while additional final state quarks that produce jets are also present. An example Feynman diagram of the qqH process can be seen in \autoref{fig:qqH}. 
    \item \textbf{Top quark plus quark associated Higgs production (tqH)}: In tqH processes, a top quark as well as a quark of a different flavour are produced alongside a Higgs boson. The Higgs boson decay may produce four muons while the additional (top) quark will produce a (b) jet. An example Feynman diagram of the tqH process can be seen in \autoref{fig:tqH}.
    \item \textbf{ZZ production from gluons (gg$\rightarrow$ZZ)}: A pair of Z bosons can be produced from a pair of initial state gluons via an intermediate quark loop. The Z boson decays may produce four muons while additional parton radiation may produce jets. An example Feynman diagram of the gg$\rightarrow$ ZZ process can be seen in \autoref{fig:ggZZ} 
    \item \textbf{ZZ production from quarks (qq$\rightarrow$ZZ)}: A pair of Z bosons can be produced from two initial state quarks. The Z boson decays may produce four muons while additional parton radiation may produce jets. An example Feynman diagram of the qq$\rightarrow$ZZ process can be seen in \autoref{fig:qqZZ}.
\end{itemize}
\begin{figure}
    \begin{subfigure}{.5\textwidth}
        \centering
        \begin{tikzpicture}
        \begin{feynman}
            %\vertex[dot, color=red, size=1mm] at (2, 0.5) {\(y_c\)};
            \vertex at (0, 1) (i1);
            \vertex at (0,-1) (i2);
            \vertex at (2, 1) (a);
            \vertex at (2, -1) (b);
            \vertex at (4, 0) (c);
            \vertex at (5, 0) (o1);
            \diagram*{
                (i1) -- [gluon, edge label'={\textit{g}}] (a),
                (i2) -- [gluon, edge label={\textit{g}}] (b),
                (a) -- [plain, edge label'={\textit{q}}] (b),
                (b) -- [plain, edge label'={\textit{q}}] (c),
                (c) -- [plain, edge label'={\textit{q}}] (a),
                (c) -- [scalar, edge label={\textit{H}}] (o1),
            };
        \end{feynman}
        \end{tikzpicture}
        \caption{The ggH process.}
        \label{fig:ggH}
        \vspace{10mm}
    \end{subfigure}%
    \begin{subfigure}{.5\textwidth}
        \centering
        \begin{tikzpicture}
        \begin{feynman}
            \vertex at (-1, 1) (i1);
            \vertex at (-1, -1) (i2);
            \vertex at (1, 1) (i3);
            \vertex at (1, -1) (i4);
            \vertex at (2, 0) (a);
            \vertex at (4, 1) (o1);
            \vertex at (4, -1) (o2);
            \vertex at (4, 0) (o3);
            \diagram*{
                (i1) -- [gluon, edge label'={\textit{g}}] (i3),
                (i2) -- [gluon, edge label={\textit{g}}] (i4),
                (i3) -- [plain, edge label'={\textit{t}}] (a),
                (i4) -- [plain, edge label={\textit{t}}] (a),
                (a) -- [scalar, edge label={\textit{H}}] (o3),
                (i3) -- [plain, edge label'={\textit{t}}] (o1);
                (i4) -- [plain, edge label={\textit{t}}] (o2);
            };
        \end{feynman}
        \end{tikzpicture}
        \caption{The ttH process.}
        \label{fig:ttH}
        \vspace{10mm}
    \end{subfigure}%
    \newline
    \begin{subfigure}{.5\textwidth}
        \centering
        \begin{tikzpicture}
        \begin{feynman}
            %\vertex[dot, color=red, size=1mm] at (2, 0.5) {\(y_c\)};
            \vertex at (-1, 1) (i1);
            \vertex at (-1,-1) (i2);
            \vertex at (0.5, 0) (a);
            \vertex at (2.5, 0) (b);
            \vertex at (4, 1) (o2);
            \vertex at (4, -1) (o1);
            \diagram*{
                (i1) -- [plain, edge label={\textit{q'}}] (a),
                (i2) -- [plain, edge label'={\textit{q}}] (a),
                (a) -- [boson, edge label'={\textit{V}}] (b),
                (b) -- [boson, edge label'={\textit{V}}] (o1),
                (b) -- [scalar, edge label={\textit{H}}] (o2),
            };
        \end{feynman}
        \end{tikzpicture}
        \caption{The VH process.}
        \label{fig:VH}
        \vspace{10mm}
    \end{subfigure}%
    \begin{subfigure}{.5\textwidth}
        \centering
        \begin{tikzpicture}
        \begin{feynman}
            \vertex at (-1, 1) (i1);
            \vertex at (-1, -1) (i2);
            \vertex at (1, 1) (i3);
            \vertex at (1, -1) (i4);
            \vertex at (2, 0) (a);
            \vertex at (4, 1) (o1);
            \vertex at (4, -1) (o2);
            \vertex at (4, 0) (o3);
            \diagram*{
                (i1) -- [plain, edge label'={\textit{q}}] (i3),
                (i2) -- [plain, edge label={\textit{q}}] (i4),
                (i3) -- [boson, edge label'={\textit{V}}] (a),
                (i4) -- [boson, edge label={\textit{V}}] (a),
                (a) -- [scalar, edge label={\textit{H}}] (o3),
                (i3) -- [plain, edge label'={\textit{q'}}] (o1);
                (i4) -- [plain, edge label={\textit{q'}}] (o2);
            };
        \end{feynman}
        \end{tikzpicture}
        \caption{The qqH process.}
        \label{fig:qqH}
        \vspace{10mm}
        \end{subfigure}%
    \newline
    \begin{subfigure}{.5\textwidth}
        \centering
        \begin{tikzpicture}
        \begin{feynman}
            \vertex at (-1, 1) (i1);
            \vertex at (-1, -1) (i2);
            \vertex at (1, 1) (i3);
            \vertex at (1, -1) (i4);
            \vertex at (2, 0) (a);
            \vertex at (4, 1) (o1);
            \vertex at (4, -1) (o2);
            \vertex at (4, 0) (o3);
            \diagram*{
                (i1) -- [plain, edge label'={\textit{q}}] (i3),
                (i2) -- [plain, edge label={\textit{b}}] (i4),
                (i4) -- [boson, edge label={\textit{W}}] (a),
                (i3) -- [boson, edge label'={\textit{W}}] (a),
                (a) -- [scalar, edge label={\textit{H}}] (o3),
                (i3) -- [plain, edge label'={\textit{q'}}] (o1);
                (i4) -- [plain, edge label={\textit{t}}] (o2);
            };
        \end{feynman}
        \end{tikzpicture}
        \caption{The tqH process.}
        \label{fig:tqH}
        \vspace{10mm}
    \end{subfigure}%
    \begin{subfigure}{.5\textwidth}
        \centering
        \begin{tikzpicture}
        \begin{feynman}
            \vertex at (-1, 1) (i1);
            \vertex at (-1, -1) (i2);
            \vertex at (0.5, 1) (i3);
            \vertex at (0.5, -1) (i4);
            \vertex at (2.5, 1) (t1);
            \vertex at (2.5, -1) (t2);
            \vertex at (4, 1) (o1);
            \vertex at (4, -1) (o2);
            \diagram*{
                (i1) -- [gluon, edge label'={\textit{g}}] (i3),
                (i2) -- [gluon, edge label={\textit{g}}] (i4),
                (i3) -- [plain, edge label={\textit{q}}] (i4),
                (i3) -- [plain, edge label'={\textit{q}}] (t1),
                (i4) -- [plain, edge label={\textit{q}}] (t2),
                (t1) -- [plain, edge label'={\textit{q}}] (t2),
                (t1) -- [boson, edge label'={\textit{Z}}] (o1);
                (t2) -- [boson, edge label={\textit{Z}}] (o2);
            };
        \end{feynman}
        \end{tikzpicture}
        \caption{The gg$\rightarrow$ZZ process.}
        \label{fig:ggZZ}
        \vspace{10mm}
        \end{subfigure}%
        \newline
    \begin{subfigure}{1.\textwidth}
        \captionsetup[subfigure]{justification=centering}
        \hspace{5cm}
        \begin{tikzpicture}
        \begin{feynman}
            \vertex at (-1, 1) (i1);
            \vertex at (-1, -1) (i2);
            \vertex at (1.5, 1) (i3);
            \vertex at (1.5, -1) (i4);
            \vertex at (4, 1) (o1);
            \vertex at (4, -1) (o2);
            \diagram*{
                (i1) -- [gluon, edge label'={\textit{g}}] (i3),
                (i2) -- [gluon, edge label={\textit{g}}] (i4),
                (i3) -- [plain, edge label={\textit{q}}] (i4),
                (i3) -- [boson, edge label'={\textit{Z}}] (o1),
                (i4) -- [boson, edge label={\textit{Z}}] (o2);
            };
        \end{feynman}
        \end{tikzpicture}
        \caption{The qq$\rightarrow$ZZ process.}
        \label{fig:qqZZ}
    \end{subfigure}%
\caption{Representative feynman diagrams of the irreducible background processes relevant to the \cHZZ analysis. This includes the ggH, ttH, VH, qqH, tqH, gg$\rightarrow$ZZ and qq$\rightarrow$ZZ processes. When no final state parton is explicitly present in the diagram it is implied via, for example, parton radiation.}
\end{figure}
\noindent The irreducible backgrounds are estimated using simulation. An overview of the samples that are used can be found in \autoref{table:IrreducibleBackgroundSamples}. Like with the \cHZZ process, additional samples are used for the bH$(ZZ\rightarrow 4\mu)$ background to account for an uncertainty related to the choice of flavour scheme. However, here the five flavour scheme (5FS) is now the nominal FS to include the bottom quark in the proton. 

\begin{table}[H]
    \centering
    \caption[]{Simulated processes used for background estimation in this work. The listed processes represent the irreducible backgrounds to the \cHZZ analysis with the exeception of the WZ$\rightarrow3\ell\nu$ process, which is used solely in the estimation of the irreducible backgrounds.}
    \begin{adjustbox}{width=0.7\textwidth}
    \label{table:IrreducibleBackgroundSamples}
        \begin{tabular}{l l l}
        \toprule 
        \textbf{Process} & \textbf{$\sigma$} & \textbf{\# of simulated events}\\
        \midrule 
        \midrule
        ggH(ZZ$\rightarrow$4L) & & xx \\
        ttH(ZZ$\rightarrow$4L) & & xx \\ 
        W$^{-}$H(ZZ$\rightarrow$4L) & & xx \\
        W$^{+}$H(ZZ$\rightarrow$4L) & & xx \\
        ZH(ZZ$\rightarrow$4L) & & xx \\
        qqH(ZZ$\rightarrow$4L) & & xx \\
        tqH(ZZ$\rightarrow$4L) & & xx \\
        gg$\rightarrow$ZZ(4$\mu$) & & xx \\
        gg$\rightarrow$ZZ(4$\tau$) & & xx \\
        gg$\rightarrow$ZZ(2$\mu$2$\tau$) & & xx \\
        qq$\rightarrow$ZZ/Z$\gamma^*\rightarrow$4L & & xx \\ 
        \midrule 
        bH 5FS FxFx & & xx \\
        bH 4FS & & xx \\
        bH 5FS & & xx \\
        \midrule
        WZ$\rightarrow3\ell\nu$ & & xx \\
        \bottomrule
        \end{tabular} 
    \end{adjustbox}
\end{table}

%%
%\begin{table}[H]
%    \centering
%    \caption[]{Simulated processes used for background estimation in this work.}
%%    \begin{adjustbox}{width=1\textwidth}
%    \label{table:IrreducibleBackgroundSamples}
%        \begin{tabular}{l l l}
%        \toprule 
%%        \textbf{Process} & \textbf{$\sigma$} & \textbf{# of simulated events}\\
%       \midrule 
%        \midrule
%        ggH(ZZ$\rightarrow$4L) & GluGluHToZZTo4L\_M125\_TuneCP5\_13TeV\_powheg2\_JHUGenV7011\_pythia8 & xx \\
%        ttH(ZZ$\rightarrow$4L) & ttH\_HToZZ\_4LFilter\_M125\_TuneCP5\_13TeV\_powheg2\_JHUGenV7011\_pythia8 & xx \\ 
%        W$^{-}$H(ZZ$\rightarrow$4L) & WminusH\_HToZZTo4L\_M125\_TuneCP5\_13TeV\_powheg2-minlo-HWJ\_JHUGenV7011\_pythia8 & xx \\
%        W$^{+}$H(ZZ$\rightarrow$4L) & WplusH\_HToZZTo4L\_M125\_TuneCP5\_13TeV\_powheg2-minlo-HWJ\_JHUGenV7011\_pythia8 & xx \\
%        ZH(ZZ$\rightarrow$4L) & ZH\_HToZZ\_4LFilter\_M125\_TuneCP5\_13TeV\_powheg2-minlo-HZJ\_JHUGenV7011\_pythia8 & xx \\
%        qqH(ZZ$\rightarrow$4L) & VBF\_HToZZTo4L\_M125\_TuneCP5\_13TeV\_powheg2\_JHUGenV7011\_pythia8 & xx \\
%        tqH(ZZ$\rightarrow$4L) & tqH\_HToZZTo4L\_M125\_TuneCP5\_13TeV-jhugenv7011-pythia8 & xx \\
%        $gg$$\rightarrow$ZZ(4$\mu$) & GluGluToContinToZZTo4mu\_TuneCP5\_13TeV-mcfm701-pythia8 & xx \\
%        $gg$$\rightarrow$ZZ(4$\tau$) & GluGluToContinToZZTo4tau\_TuneCP5\_13TeV-mcfm701-pythia8 & xx \\
%        $gg$$\rightarrow$ZZ(2$\mu$2$\tau$) & GluGluToContinToZZTo2mu2tau\_TuneCP5\_13TeV-mcfm701-pythia8 & xx \\
%        qq$\rightarrow$ZZ/Z$\gamma^*\rightarrow$4L & ZZTo4L\_TuneCP5\_13TeV\_powheg\_pythia8 & xx \\ 
%        \midrule 
%        bH 5FS FxFx & HPlusBottom\_5FS\_MuRFScaleDynX0p50\_HToZZTo4L\_M125\_TuneCP5\_13TeV\_amcatnloFXFX\_JHUGenV7011\_pythia8 & xx \\
%        bH 4FS & HPlusBottom\_4FS\_MuRFScaleDynX0p50\_HToZZTo4L\_M125\_TuneCP5\_13TeV\_amcatnlo\_JHUGenV7011\_pythia8 & xx \\
%        bH 5FS & HPlusBottom\_5FS\_MuRFScaleDynX0p50\_HToZZTo4L\_M125\_TuneCP5\_13TeV\_amcatnlo\_JHUGenV7011\_pythia8 & xx \\
%        \midrule
%        WZ$\rightarrow3\ell\nu$ & WZTo3LNu\_TuneCP5\_13TeV-amcatnloFXFX-pythia8 & xx \\
%        \bottomrule
%        \end{tabular} 
%    \end{adjustbox}
%\end{table}

\subsection{Estimation of reducible backgrounds}
\label{sec:ReducibleBackgrounds}
Reducible background processes are background processes that do not produce the same final state particles as the signal process but where mis-identification of physics objects can still falsify the sought-after signature. Since jets are typically abundant in most collisions, this amounts to the mis-identification of additional muons for this analysis. Major contributions to this background are expected to come from the Drell-Yan process while other processes which may produce at least two leptons, such as t$\overline{\mathrm{t}}$, may also contribute. Example Feynman diagrams of these two processes can be seen in \autoref{fig:reducibleBackgroundDiagrams}. Since the simulation of mis-identified muons is subject to significant modelling uncertainties, a data-driven approach may be used. This involves determining the mis-identification rate of muons in data and applying it to a side-band region from which the contributions of reducible backgrounds are extrapolated into the signal region. This methodology is presented in this section and follows that which is used in \cite{HIG19-001}.

\begin{figure}
    \begin{subfigure}{.5\textwidth}
        \centering
        \begin{tikzpicture}
        \begin{feynman}
            %\vertex[dot, color=red, size=1mm] at (2, 0.5) {\(y_c\)};
            \vertex at (0, 1) (i1);
            \vertex at (0,-1) (i2);
            \vertex at (1, 0) (a);
            \vertex at (3, 0) (b);
            \vertex at (4, -1) (o2);
            \vertex at (4, 1) (o1);
            \diagram*{
                (i1) -- [plain, edge label'={\textit{q}}, near start] (a),
                (i2) -- [plain, edge label={\textit{q}}, near start] (a),
                (a) -- [boson, edge label'={\textit{Z}}] (b),
                (b) -- [plain, edge label'={\textit{$\mu$}}, near end] (o1),
                (b) -- [plain, edge label={\textit{$\mu$}}, near end] (o2),
            };
        \end{feynman}
        \end{tikzpicture}
        \caption{The Drell-Yan process.}
        \vspace{10mm}
    \end{subfigure}%
    \begin{subfigure}{.5\textwidth}
        \centering
        \begin{tikzpicture}
        \begin{feynman}
            %\vertex[dot, color=red, size=1mm] at (2, 0.5) {\(y_c\)};
            \vertex at (0, 1) (i1);
            \vertex at (0,-1) (i2);
            \vertex at (1, 0) (a);
            \vertex at (3, 0) (b);
            \vertex at (4, -1) (o2);
            \vertex at (4, 1) (o1);
            \diagram*{
                (i1) -- [gluon, edge label'={\textit{g}}, near start] (a),
                (i2) -- [gluon, edge label={\textit{g}}, near start] (a),
                (a) -- [gluon, edge label'={\textit{g}}] (b),
                (b) -- [plain, edge label'={\textit{t}}, near end] (o1),
                (b) -- [plain, edge label={\textit{t}}, near end] (o2),
            };
        \end{feynman}
        \end{tikzpicture}
        \caption{The t$\overline{\mathrm{t}}$ process.}
        \vspace{10mm}
    \end{subfigure}%
\caption{Representative feynman diagrams of the Drell-Yan and t$\overline{\mathrm{t}}$ processes, which are expected to contribute significantly to the reducible background of the \cHZZ analysis. Jets are produced via for example parton radiation for the Drell-Yan process, while the decay of the top quarks in the t$\overline{\mathrm{t}}$ process automatically produces b jets from the hadronisation of b quarks.}
\label{fig:reducibleBackgroundDiagrams}
\end{figure}

\subsubsection{Determination of muon mis-identification rate}
To determine the mis-identification of muons with respect to the tight muon requirement outlined in \autoref{sec:MuonReconstruction}, a three-muon selection is applied to data. Specifically, events with a $Z\rightarrow\mu^+\mu^-$ decay that also contain a third muon are targeted. Since hard-scattering processes that produces a Z boson are not expected to produce any additional muons, the third reconstructed muon (typically referred to as the \textit{probe muon}) is assumed to be one that is mis-identified as such. To determine a mis-identification rate, the ratio of probe muons that pass the tight muon requirement with respect to those that pass the loose muon requirement is calculated. This procedure is performed in bins of the probe muon \pt for the barrel ($\lvert \eta \rvert \leq 1.2$) and endcap ($\lvert \eta \rvert > 1.2$) regions respectively. The exact reconstruction algorithm that is applied is the following:
\begin{enumerate}
    \item Events that contain at least two muons that pass the tight identification requirement and where the third passes at least the loose identification requirement are chosen. The \pt-leading muon is required to satisfy \pt \, \textgreater 20 GeV and the sub-leading muon is required to satisfy \pt \,\textgreater 10 GeV. Additionally, the HLT\_IsoMu24 trigger requirement must also be met. Lastly, to ensure two muons are not spuriously reconstructed from shared tracks, it is required that each muon candidate is separated from the others by $\Delta$R \textgreater 0.02.
    \item Opposite-sign muon pairs are merged into Z boson candidates and the candidate closest to the nominal Z mass is taken as the final Z candidate. Additionally, the invariant mass of any combination of oppsite-sign muons must satisfy $m_{\mu\mu}$\textgreater \, 4 GeV, to remove any contributions from low mass resonances such as J/$\psi$. 
    \item The remaining, third muon not selected as part of the Z candidate is taken as the probe muon 
\end{enumerate}
The mis-identification rate of the probe muon that is determined in this way in bins of the probe muon \pt, can be seen in \autoref{fig:misIDRate}. However, the contribution from processes that indeed produce three muons in the hard-scattering  must be subtracted. This consists primarily of WZ$\rightarrow3\ell\nu$ processes that artifically inflate the calculated mis-identification rate at higher probe muon \pt. This contribution is subtracted using simulation. It is this corrected version of the mis-identification rate that is used in the following section. 

\subsubsection{Application of muon mis-identification rate}
The muon mis-identification rate is applied to a control region to estimate the contribution of reducible backgrounds to the previously described \cHZZ selection. It is useful to introduce some of the related terminology at this point. The four pass (4P) region henceforth refers to the inclusive signal region that is defined via the \cHZZ selection. The three-pass-one-fail (3P1F) and two-pass-two-fail (2P2F) regions respectively refer to regions in which the \cHZZ reconstruction is performed as previously described but where only three (two) of the muons satisfy the tight identification criteria and the remaining one (two) muon(s) satisfy only the loose identification criteria. The 3P1F and 2P2P are collectively referred to as the application region (AR). \\
\\
The extrapolation of the AR to the 4P is performed using the previously determined mis-identification rate. The prescription for this application can be obtained from the mis-identification rate $f_i$ which is defined as
\begin{align}
    f = \frac{N_{\mathrm{tight}}}{N_{\mathrm{loose}}}. 
\end{align}
Here $N_{\mathrm{loose}}$ and $N_{\mathrm{tight}}$ are the number of probe muons in a given bin that pass the loose and tight identification criteria respectively. From this, the relation 
\begin{align}
\label{eq:tightloosef}
    N_{\mathrm{tight}} = N_{\mathrm{loose}} f
\end{align}
follows. Since one is interested in the contributions of muons which pass the loose but not the tight identification requirement in the AR, \autoref{eq:tightloosef} can be reinterpereted as
\begin{align}
\label{eq:tightloosenottightf}
    N_{\mathrm{loose-not-tight}} = N_{\mathrm{loose}} (1-f).
\end{align}
By substituting this back into \autoref{eq:tightloosef}, the desired prescription is found:
\begin{align}
\label{eq:extrapolationprescription}
    N_{\mathrm{tight}} = N_{\mathrm{loose-not-tight}} \frac{f}{(1-f)}.
\end{align}
Thus, for each muon that fails the tight identification requirements but passes the loose ones in the 3P1F and 2P2F regions, the weight $f/(1-f)$ is applied, where $f$ is the \pt \, and $\eta$ dependant muon misidentification rate. This leads to the following expressions for the individual contributions of the AR to the 4P region:

\begin{enumerate}
    \item \textbf{2P2F}: Since this region contains two muons that pass the loose identification criteria but not the tight, the weight $f/(1-f)$ must be applied twice. The total contribution of this region in the 4P region can thus be written as

    \begin{align}
        N_{\mathrm{4P}}^{\mathrm{(2P2F)}} = \sum_{k}^{N_{\mathrm{2P2F}}} \frac{f_k^{(3)}}{(1-f_k^{(3)})} \frac{f_k^{(4)}}{(1-f_k^{(4)})},
    \end{align}

    where the $f_k^{(3/4)}$ is the misidentification rate associated with each of the non-passing muon for the $k$-th event. Major contributors to the 2P2F region are expected to be Drell-Yan and $t\overline{t}$ processes, which produce only two prompt muons. 

    \item \textbf{3P1F}: Since this region contains only one muon that passes the loose identification criteria but not the tight, the weight $f/(1-f)$ is only applied. The total contribution of this region in the 4P region can thus be written as

    \begin{align}
        N_{\mathrm{4P}}^{\mathrm{(3P1F)}} = \sum_{k}^{N_{\mathrm{3P1F}}}\frac{f_k^{(4)}}{(1-f_k^{(4)})},
    \end{align}

    where the $f_k^{(4)}$ is the misidentification rate associated with the non-passing muon for the $k$-th event. The major contributor to the 3P1F ragion is expected to consist of WZ$\rightarrow3\ell\nu$ due to the presence of three prompt leptons. 
\end{enumerate}
To obtain the total contribution of the AR to the 4P region, potential contaminations of the 2P2F and 3P1F regions must be accounted for. The first source of contamination is the potential overlap of the 3P1F region with contributions from the 2P2F region, where an additional muon has been mis-identified in the former and erroneously passes the tight identificatio criteria. This may lead to an overestimation of the 3P1F region. Such contributions can be estimated via the term
\begin{align}
    N_{\mathrm{exp.}}^{\mathrm{(3P1F)}} = \sum_{k}^{N_{\mathrm{2P2F}}} \big(\frac{f_k^{(3)}}{(1-f_k^{(3)})} + \frac{f_k^{(4)}}{(1-f_k^{(4)})} \big).
\end{align}
Effectively, contributions from the 2P2F region are weighed with the mis-identification rate for both muons that fail the tight identification criteria. To then extrapolate this contribution to the 4P region, the fake rate must once again be applied, this time to the respective complementary muon. This produces the final term
\begin{align}
    N_{\mathrm{4P exp.}}^{\mathrm{(3P1F)}} =& \sum_{k}^{N_{\mathrm{2P2F}}} \big(\frac{f_k^{(3)}}{(1-f_k^{(3)})} \frac{f_k^{(4)}}{(1-f_k^{(4)})} + \frac{f_k^{(4)}}{(1-f_k^{(4)})}\frac{f_k^{(3)}}{(1-f_k^{(3)})} \big) \\
    = & 2 \sum_{k}^{N_{\mathrm{2P2F}}}\big(\frac{f_k^{(3)}}{(1-f_k^{(3)})} \frac{f_k^{(4)}}{(1-f_k^{(4)})})
\end{align}
\\
\\
\noindent An additional source of potential contamination is the contribution of four muon processes in which muons either fail the tight identification criteria or fall outside the detector acceptance. This is primarily relevant in the 3P1F region with contributions from qq$\rightarrow$ZZ/Z$\gamma^*\rightarrow$4L processes, which again lead to an overestimation of the 3P1F region. Contributions to the 4P region from this, denoted with $N_{\mathrm{4P}}^{\mathrm{(ZZ, 3P1F)}}$ are estimated via simulation with the same prescription as data events in the 3P1F region:
\\
\begin{align}
    N_{\mathrm{4P}}^{\mathrm{(ZZ, 3P1F)}} = \sum_{k}^{N_{\mathrm{3P1F}}^{ZZ}}\frac{f_k^{(4)}}{(1-f_k^{(4)})},
\end{align}
\\
The total contribution to the 4P region $N_{\mathrm{4P}}$ may finally be estimated by taking the sum of the 2P2F and 3P1F contributions and subtracting the discussed contamination terms. This leads to
\begin{align}
    N_{\mathrm{4P}} =& N_{\mathrm{4P}}^{\mathrm{(2P2F)}} + N_{\mathrm{4P}}^{\mathrm{(3P1F)}} - N_{\mathrm{4P exp.}}^{\mathrm{(3P1F)}} - N_{\mathrm{4P}}^{\mathrm{(ZZ, 3P1F)}} \\
    =& \sum_{k}^{N_{\mathrm{3P1F}}}\frac{f_k^{(4)}}{(1-f_k^{(4)})} - \sum_{k}^{N_{\mathrm{3P1F}}^{ZZ}}\frac{f_k^{(4)}}{(1-f_k^{(4)})} - \sum_{k}^{N_{\mathrm{2P2F}}}\big(\frac{f_k^{(3)}}{(1-f_k^{(3)})} \frac{f_k^{(4)}}{(1-f_k^{(4)})})
\end{align}
\\
However, it is found that due to the strong muon identification criteria an extremely small yield of reducible backgrounds are observed. Since this leads to non-continuous distributions of observables, a simplification must be made for the final statistical evaluation. 

...

\section{Validation of \cHZZ event selection in sideband regions}
\label{sec:sidebandValidation}
Here, a validation of the described event selection is presented. Specifically, the 2018 dataset of the CMS detector is compared to simulation in sideband regions of the signal for a variety of observables. These side-band regions include all selected events outside of the 120 GeV \textless $m$(H) \textgreater 130 GeV region, which is where the \cHZZ is expected to be found. The .. 
\section{Statistical inference}
\label{sec:StatisticalEvaluation}
For the statistical inference process, both the \textsf{DeepJet} CvsB and CvsL discriminators are used in a pseuo-two-dimensional fit. Specifically, an \textit{unrolling} process is applied to events to project the two-dimensional information given by the CvsB and CvsL discriminators into a single discriminator. This involves constructing a histogram of the CvsB discriminator in bins of the corresponding CvsL value. The resulting histogram can be seen in \autoref{fig:UnrolledFinalHist}. It is on these distributions that the statistical inference process described in the following is performed. This consists of constructing a statistical model with which a fit may be performed as described in \autoref{sec:statisticalModel} as well as an uncertainty model, as described in \autoref{sec:uncertaintyModel}\\
\\
\subsection{Statistical model}
\label{sec:statisticalModel}
Assuming the absence of a measurable signal, a upper limit on $\sigma$BR(\cHZZ) may be set. This in turn may be interpreted as a limit on \kappac \, using the prescription derived in \autoref{sec:kappaframework}. To do this, a statistical model is required to predict the distribution of the number entries in each bin of the discriminator histogram according to a given hypothesis. Since each of the bins are filled in a discrete couting process, a Poissonian Ansatz with 
\begin{align}
    \mathcal{P}(k; \lambda) = \frac{\lambda^{k} e^{-\lambda}}{k!}
\end{align}
is appropriate. Here, $\lambda$ denotes the expectation value with $k$ observed events. In the $i$-th bin of the discriminator distribution, the expecation value $\lambda_i$ is calculated using the models of the signal and background processes discussed in \autoref{sec:s+bEstimation}. This amounts to $\lambda_i = \mu s_i + b_i$ where $s_i$ and $b_i$ are the signal and background estimations respectively. The signal strength modifier $\mu$ allows for an arbitrary scaling of the signal contribution and is used as a floating parameter in the inference process. From this, a combined binned likelihood function 
\begin{align}
    \label{binned_likelihood}
    \mathcal{L} (d \, | \, \mu \cdot s(\bm{\theta}) + b(\bm{\theta})) = \prod_{i \in \mathrm{bins}} \mathcal{P}(d_i \, | \, \mu \cdot s(\bm{\theta}) + b(\bm{\theta})) \, \,  \mathrm{x} \prod_{j \in \mathrm{nuis.}} \mathcal{C} ({\hat{\theta_j}} \, | \, \theta_j).
\end{align}
may be derived for some set of measured data $d_i$. Here, an uncertainty model is introduced via the nuisance parameters $\bm{\theta}$ that account for uncertainties related to the signal and background estimation. These follow a distribution $\mathcal{C}$ and may alter the scaling of the signal and background contributions as well as their histogram shape with respect to the discriminator that is us. The estimate of $\bm{\theta}$ that is used to obtain estimations of $s_i$ and $b_i$ in the inference process is denoted by $\bm{\hat{\theta}}$ and is found by finding the global maximum of the likelihood. The specifics of the uncertainty model employed in this analysis are discussed in \autoref{sec:uncertaintyModel}. Since the statistical evaluation is not applied to data in this analysis, an Asimov dataset \cite{AsimovMaybe?} is used. To compare different hypotheses, the test statistic that is used is the \textit{profile likelihood ratio}
\begin{align}
    \label{test_statistic}
 q_{\mu} = -2 \mathrm{ln}\Bigg(\frac{\mathcal{L} (d \, | \, \mu \cdot s(\bm{\hat{\theta}_{\mu}}) + b(\bm{\hat{\theta}_{\mu}}))}{\mathcal{L} (d \, | \, \hat{\mu} \cdot s(\bm{\hat{\theta}}) + b(\bm{\hat{\theta}}))} \Bigg),
\end{align}
where ($\hat{\mu}$, $\hat{\bm{\theta}}$) are the parameter values that globally maximise the likelihood while $\bm{\hat{\theta}_{\mu}}$ maximises the likelihood for a given $\mu$. A significant advantage of this test statistic is that in the large sample limit, the distribution $f(q \, | \mu)$ approaches the $\chi^2_k$ distribution with $k=1$ degrees of freedom, according to Wilk's theorem \cite{wilksTheorem}. This is very useful as knowing the distribution of the test statistic allows one to calculcate a p-value 

\begin{align}
    p_{\mu} = \int_{q_{\mathrm{obs.}}}^{\infty} f(q \, | \, \mu) \mathrm{d}q .
\end{align}
With this p-value, the \CLs method may be applied \cite{CLs}. For this, a \CLs value 
\begin{align}
    \mathrm{CL_s} = \frac{p_{\mu}}{1 - p_0} = \frac{\int_{q_{\mathrm{obs.}}}^{\infty} f( q \, | \, \mu) \, \mathrm{d}q}{\int_{q_{\mathrm{obs.}}}^{\infty} f( q \, | \, 0) \, \mathrm{d}q} .
\end{align}
is computed. A feature of this method is that large overlaps of test statistic distributions between the $H_{\mu}$ and $H_{0}$ hypotheses, due to the very small signal cross section associated with $H_{\mu}$, are accounted for. This is achieved by weighting $p_{\mu}$ with $(1 - p_{0})^{-1}$, thus decreasing the \CLs value with larger overlaps.

\subsection{Uncertainty model}
The sources of uncertainty in the model of the signal and background processes are described in this section. These consist of two types. The first are shape uncertainties, which may change the normalisation as well as the shape of the distributions in question. These uncertainties are captured by creating variations of these distributions that are interpreted as $\pm 1\sigma$ variations. The second type consists of normalisation uncertainties. These only affect the normalisation of distributions without affecting the shape and can thus be captured as a single, real paarameter. Both types of uncertainties are associated with respective nuisance parameters in the statistical model introduced in \autoref{sec:statisticalModel}.
\subsubsection{Theoretical uncertainties common to simulation}
A number of theoretical uncertainties that are common to all simulated sample are included in the uncertainty model. This includes:
\begin{itemize}
    \item Shape uncertainties related to the choice of the normalisation and factorisation scales $\mu_R$ and $\mu_F$. These are varied independently by factors of 2 and 0.5 using a reweighting technique that is applied to the simulation, thus introducing four shape-changing nuisance parameters. 
    \item Shape uncertainties related to the modelling of the Parton Distribution Function (PDF). These uncertainties are obtained from the \textsf{NNPDF3.1} PDF set that is used in simulation \cite{NNPDF3.1} and includes 100 PDF variations associated with variations of individual parameters. These are combined into a single nuisance parameter with the prescription   
    \begin{equation}
    \label{eq:symmhessian}
    \sigma^+ = \sigma^- = \sqrt{\sum_{i=1}^{N_{\text{par}}} \left( F_i - F_0 \right)^2}\,,
    \end{equation}
    where $F_0$ is the nominal value of the observable in question and $F_i$ is the varied value associated with one of the $N_{\text{par}}$ parameter variations \cite{Butterworth_2016}.
    \item Normalisation uncertainties related to the cross sections of the individual processes. These are:
        \begin{itemize}
            \item{Higgs production and branching ratio uncertainties taken from \cite{HiggsHandBook}}
            \item{A 50\% normalisation uncertainty on the modelling of the gluon fusion process in association with heavy quarks ?? Ask gerrit. }
            \item{Other process uncertainties...}
        \end{itemize}
    \item Shape uncertainties related to the tuning of the parton showering used in the generator. These are implemented by varying parameters related to initial-state radiation and final-state radiation independently, introducing two nuisance parameters. 
    \item A shape uncertainty related to the application of a pile-up reweighting procedure, with which the pile-up profile of simulation is matched to that of data. These uncertainties are captured via a single nuisance parameter. 
\end{itemize}
\subsubsection{Experimental uncertainties common to simulation}
The following experimental uncertainties are common to all simulated sample:
\begin{itemize}
    \item Shape uncertainties related to the jet energy scale. For this, a simplified schema is used in which closely correlated uncertainty sources are grouped and captured across 11 individual nuisance parameters. Sources of uncertainty include for example the limited set of data available for the calibration procedure or differences in calibration response to different jet flavours. 
    \item A shape uncertainty related to the smearing method used to correct the jet energy resolution. This is captured via a single nuisance parameter.
    \item Shape uncertainties related to the calibration of the jet flavour-tagging algorithm that is used. These are captured via 13 nuisance parameters and include for example uncertainty sources related to the individual phase spaces targeted in the calibration or the limited set of avaialble data. 
    \item A shape uncertainty related to the pile-up identification method that is used. This is captured via a single nuisance parameter.
    \item Shape uncertainties related to the muons used in the analysis. The response of the muon identification criteria, the isolation as well as the muon trigger path in simulation is calibrated to match data. Uncertainties associated with this calibration are captured via a nuisance parameter. 
    \item A normalisation uncertainty related to the luminosity with which the simulation is scaled, which is known with a limited precision. This amounts 2.5\% for the 2018 dataset and is caputured as a single nuisance parameter. 
\end{itemize}
\subsubsection{Uncertainties related to \cHZZ and \bHZZ modelling}
A systematic uncertainty that is unique to \cHZZ and \bHZZ is that associated with the use of a specific flavour scheme. As discussed in \autoref{sec:cHSimulation}, an envelope representing a $\pm 1\sigma$ variation is extracted from the respective 3FS (4FS) and 4FS (5FS) samples and applied to the nominal \cHZZ 4FS FxFx (\bHZZ 5FS FxFx) sample.
\subsubsection{Uncertainties related to reducible background modelling}
Due to the almost neglible nature of the reducible background contribution, a simple normalisation uncertainty is introduced to account for uncertainties associated with this estimation procedure...
\subsubsection{Uncertainties related to statistical precision of background estimation}
Simulation estimation methods themselves include a statistical uncertainty due to the limited number of events that are generated to estimate each process. This results in the introduction of nuisance parameter per process per bin of the final discriminator. This can be simplified to introducing only a single, per bin nuisance parameter by using the Barlow-Beeston approach \cite{Barlow-Beeston}.
\section{Results}
In this section, the result of the presented methods is discussed. 
\label{sec:uncertaintyModel} 

